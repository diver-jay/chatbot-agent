import streamlit as st
import time
from langchain_core.runnables.history import RunnableWithMessageHistory

# ë¶„ë¦¬ëœ ëª¨ë“ˆ ì„í¬íŠ¸
from prompt_loader import ToneAwarePromptLoader
from model_factory import ChatModelFactory
from response_processor import split_response_by_context
# from image_selector import select_image_for_context
from session_manager import get_session_history
from ui_components import sidebar_api_input, display_previous_messages
from tone_selector import ToneSelector

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹¬ì‹¬ì´ ìŠ¤íƒ€ì¼ ì±—ë´‡",
    page_icon="ğŸ˜Š",
    layout="wide"
)

# ì»¤ìŠ¤í…€ ìŠ¤í”¼ë„ˆ CSS
st.markdown("""
<style>
.wave-loader {
    display: flex;
    justify-content: flex-start;
    align-items: center;
    gap: 4px;
    padding: 8px 0;
    margin-left: 20px;
}
.wave-loader .dot {
    width: 6px;
    height: 6px;
    background-color: #ff4b4b;
    border-radius: 50%;
    animation: wave 1.2s ease-in-out infinite;
}
.wave-loader .dot:nth-child(1) {
    animation-delay: 0s;
}
.wave-loader .dot:nth-child(2) {
    animation-delay: 0.2s;
}
.wave-loader .dot:nth-child(3) {
    animation-delay: 0.4s;
}
@keyframes wave {
    0%, 60%, 100% {
        transform: translateY(0);
    }
    30% {
        transform: translateY(-10px);
    }
}

/* ë¡œë”© í™”ë©´ìš© í° wave-loader */
.wave-loader-large {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 12px;
    padding: 20px 0;
}
.wave-loader-large .dot {
    width: 20px;
    height: 20px;
    background-color: #ff4b4b;
    border-radius: 50%;
    animation: wave 1.2s ease-in-out infinite;
}
.wave-loader-large .dot:nth-child(1) {
    animation-delay: 0s;
}
.wave-loader-large .dot:nth-child(2) {
    animation-delay: 0.2s;
}
.wave-loader-large .dot:nth-child(3) {
    animation-delay: 0.4s;
}
</style>
""", unsafe_allow_html=True)


# ìºì‹±ëœ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource(show_spinner=False)
def load_cached_chat_model(model_name, api_key):
    return ChatModelFactory.create_model(model_name, api_key)


# ìºì‹±ëœ í”„ë¡¬í”„íŠ¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_data()
def load_cached_prompt(prompt_path):
    """
    ì§€ì •ëœ tone íŒŒì¼ ê²½ë¡œë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        tone_file_path: tone í…œí”Œë¦¿ íŒŒì¼ ê²½ë¡œ
    """
    loader = ToneAwarePromptLoader(prompt_path=prompt_path)
    return loader.load()


# ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ í™”ë©´
def show_influencer_input_screen():
    # ë¡œë”© ìƒíƒœ í™•ì¸
    if st.session_state.get('loading', False):
        # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ì„ ì¤‘ì•™ì— í‘œì‹œ
        st.markdown("<br><br><br><br><br><br><br><br>", unsafe_allow_html=True)

        influencer_name = st.session_state.get('temp_influencer_name', '')

        # ì¤‘ì•™ ì •ë ¬ëœ í…ìŠ¤íŠ¸ì™€ í° ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ë§Œ í‘œì‹œ
        st.markdown(f"""
        <div style="text-align: center;">
            <h2>AI {influencer_name}ë¥¼ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤...</h2>
            <br><br>
            <div class="wave-loader-large">
                <div class="dot"></div>
                <div class="dot"></div>
                <div class="dot"></div>
            </div>
        </div>
        """, unsafe_allow_html=True)

        # AIë¥¼ ì‚¬ìš©í•˜ì—¬ Tone ì„ íƒ
        chat_model = load_cached_chat_model("claude-3-7-sonnet-latest", st.session_state.anthropic_api_key)
        tone_selector = ToneSelector(chat_model)

        # Tone ì„ íƒ (ë¡œê·¸ ìë™ ì¶œë ¥ë¨)
        tone_type, tone_file_path = tone_selector.select_tone(influencer_name)

        # ì„¸ì…˜ì— ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ë° Tone ì •ë³´ ì €ì¥
        st.session_state.influencer_name = influencer_name
        st.session_state.tone_type = tone_type
        st.session_state.tone_file_path = tone_file_path
        st.session_state.setup_complete = True
        st.session_state.loading = False

        st.rerun()
        return

    # ì¼ë°˜ ì…ë ¥ í™”ë©´
    st.title("ğŸŒŸ ë‚˜ë§Œì˜ AI ì¹œêµ¬ ë§Œë“¤ê¸°")
    st.markdown("### ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ì¸í”Œë£¨ì–¸ì„œì˜ ì´ë¦„ì„ ì¨ì£¼ì„¸ìš”")

    influencer_name = st.text_input(
        "ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„",
        placeholder="ì˜ˆ: ë°•ì‚¬ë‹˜, ìµœì• , ì¹œêµ¬ ì´ë¦„ ë“±...",
        key="influencer_name_input",
        label_visibility="collapsed"
    )

    _, col2, _ = st.columns([1, 1, 1])
    with col2:
        if st.button("ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
            if influencer_name.strip():
                # ë¡œë”© ìƒíƒœë¡œ ì „í™˜
                st.session_state.temp_influencer_name = influencer_name.strip()
                st.session_state.loading = True
                st.rerun()
            else:
                st.warning("ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")


# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ UI
def main():
    # ì‚¬ì´ë“œë°” í‘œì‹œ
    sidebar_api_input()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'setup_complete' not in st.session_state:
        st.session_state.setup_complete = False

    # API í‚¤ê°€ ë“±ë¡ë˜ì§€ ì•Šì€ ê²½ìš° ì•Œë¦¼ í‘œì‹œ
    if not st.session_state.get('api_key_submitted', False):
        st.info("ì±„íŒ…ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ Anthropic API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        st.chat_input("API í‚¤ë¥¼ ë¨¼ì € ë“±ë¡í•˜ì„¸ìš”", disabled=True)
        return

    # ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ í™”ë©´ í‘œì‹œ
    if not st.session_state.setup_complete:
        show_influencer_input_screen()
        return

    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([3, 1])

    with col1:
        st.title("ì‹¬ì‹¬ì´ ìŠ¤íƒ€ì¼ ì±—ë´‡ ğŸ’¬")
        st.markdown("""ì¹œí•œ ì¹œêµ¬ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”!
        ì–´ë–¤ ì¼ìƒ ì´ì•¼ê¸°ë“  í™˜ì˜ì´ì—ìš” ğŸ˜Š""")

    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    display_previous_messages()

    # API ëª¨ë¸ ë¡œë“œ
    chat_model = load_cached_chat_model("claude-3-7-sonnet-latest", st.session_state.anthropic_api_key)

    # ì„ íƒëœ Toneìœ¼ë¡œ ëŒ€í™” ì²´ì¸ êµ¬ì„±
    tone_file_path = st.session_state.get('tone_file_path', "prompts/converstation_prompt.md")

    # tone_file_pathë¡œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt = load_cached_prompt(tone_file_path)

    chain = prompt | chat_model
    conversation = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history"
    )

    # ì±„íŒ… ì…ë ¥ í™œì„±í™”
    if question := st.chat_input("ì˜¤ëŠ˜ ë­í–ˆì–´?"):
        # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥ ë° í‘œì‹œ
        st.session_state.messages.append({"role": "human", "content": question})
        with st.chat_message('human'):
            st.markdown(question)

        # ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        # ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •
        max_retries = 3
        retry_count = 0
        spinner_placeholder = st.empty()
        error_placeholder = st.empty()

        while retry_count < max_retries:
            try:
                # ëŒ€í™” ì²´ì¸ì„ í†µí•œ ì‘ë‹µ ìƒì„±
                spinner_placeholder.markdown('<div class="wave-loader"><div class="dot"></div><div class="dot"></div><div class="dot"></div></div>', unsafe_allow_html=True)

                result = conversation.invoke(
                    {"input": question},
                    config={"configurable": {"session_id": "default"}}
                )
                response = result.content

                # # ì‘ë‹µì— ë§ëŠ” ì´ë¯¸ì§€ ì„ íƒ
                # selected_image = select_image_for_context(response)

                # Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ë§¥ë½ ë‹¨ìœ„ë¡œ ë¶„í• 
                split_parts = split_response_by_context(response, chat_model)

                spinner_placeholder.empty()
                error_placeholder.empty()

                # ë¶„í• ëœ ë‹µë³€ì„ ê°œë³„ ë©”ì‹œì§€ë¡œ í‘œì‹œ
                for i, part in enumerate(split_parts):
                    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ì•„ë‹ˆë©´ íƒ€ì´í•‘ ì¤‘ í‘œì‹œ
                    if i > 0:
                        typing_placeholder = st.empty()
                        typing_placeholder.markdown('<div class="wave-loader"><div class="dot"></div><div class="dot"></div><div class="dot"></div></div>', unsafe_allow_html=True)
                        time.sleep(4)  # íƒ€ì´í•‘ ì¤‘ ì‹œë®¬ë ˆì´ì…˜
                        typing_placeholder.empty()

                    with st.chat_message('assistant'):
                        st.markdown(part)

                # # ì´ë¯¸ì§€ í‘œì‹œ (ì„ íƒëœ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°)
                # if selected_image:
                #     st.image(selected_image, width=200)

                # ë©”ì‹œì§€ ì €ì¥ (ì´ë¯¸ì§€ ê²½ë¡œë„ í•¨ê»˜ ì €ì¥)
                message_data = {"role": "assistant", "content": response}
                # if selected_image:
                #     message_data["image"] = selected_image
                st.session_state.messages.append(message_data)
                break  # ì„±ê³µí•˜ë©´ ë°˜ë³µ ì¤‘ë‹¨

            except Exception as e:
                error_text = str(e)
                retry_count += 1
                spinner_placeholder.empty()

                # ì˜¤ë¥˜ íƒ€ì… í™•ì¸ ë° ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ ìƒì„±
                if "overloaded_error" in error_text or "529" in error_text:
                    if retry_count < max_retries:
                        with error_placeholder.container():
                            with st.chat_message('assistant'):
                                st.warning(f"âš ï¸ ì¬ì‹œë„ ì¤‘... ({retry_count}/{max_retries})")
                        time.sleep(2)  # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
                    else:
                        spinner_placeholder.empty()
                        error_placeholder.empty()
                        error_final = "âš ï¸ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        with st.chat_message('assistant'):
                            st.error(error_final)
                        st.session_state.messages.append({"role": "assistant", "content": error_final})
                else:
                    spinner_placeholder.empty()
                    error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_text}"
                    with st.chat_message('assistant'):
                        st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    break  # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ

if __name__ == "__main__":
    main()
