import streamlit as st
import time
from langchain_core.runnables.history import RunnableWithMessageHistory

# ë¶„ë¦¬ëœ ëª¨ë“ˆ ì„í¬íŠ¸
from prompt_loader import ToneAwarePromptLoader
from model_factory import ChatModelFactory
from response_processor import split_response_by_context
# from image_selector import select_image_for_context
from session_manager import get_session_history
from ui_components import sidebar_api_input, display_previous_messages
from tone_selector import ToneSelector
from search_service import SearchService
from term_detector import TermDetector
from entity_detector import EntityDetector

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹¬ì‹¬ì´ ìŠ¤íƒ€ì¼ ì±—ë´‡",
    page_icon="ğŸ˜Š",
    layout="wide"
)

# ì»¤ìŠ¤í…€ ìŠ¤í”¼ë„ˆ CSS
st.markdown("""
<style>
.wave-loader {
    display: flex;
    justify-content: flex-start;
    align-items: center;
    gap: 4px;
    padding: 8px 0;
    margin-left: 20px;
}
.wave-loader .dot {
    width: 6px;
    height: 6px;
    background-color: #ff4b4b;
    border-radius: 50%;
    animation: wave 1.2s ease-in-out infinite;
}
.wave-loader .dot:nth-child(1) {
    animation-delay: 0s;
}
.wave-loader .dot:nth-child(2) {
    animation-delay: 0.2s;
}
.wave-loader .dot:nth-child(3) {
    animation-delay: 0.4s;
}
@keyframes wave {
    0%, 60%, 100% {
        transform: translateY(0);
    }
    30% {
        transform: translateY(-10px);
    }
}

/* ë¡œë”© í™”ë©´ìš© í° wave-loader */
.wave-loader-large {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 12px;
    padding: 20px 0;
}
.wave-loader-large .dot {
    width: 20px;
    height: 20px;
    background-color: #ff4b4b;
    border-radius: 50%;
    animation: wave 1.2s ease-in-out infinite;
}
.wave-loader-large .dot:nth-child(1) {
    animation-delay: 0s;
}
.wave-loader-large .dot:nth-child(2) {
    animation-delay: 0.2s;
}
.wave-loader-large .dot:nth-child(3) {
    animation-delay: 0.4s;
}
</style>
""", unsafe_allow_html=True)


# ìºì‹±ëœ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource(show_spinner=False)
def load_cached_chat_model(model_name, api_key):
    return ChatModelFactory.create_model(model_name, api_key)


# ìºì‹±ëœ í”„ë¡¬í”„íŠ¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_data()
def load_cached_prompt(prompt_path, influencer_name=None, persona_context=None):
    """
    ì§€ì •ëœ tone íŒŒì¼ ê²½ë¡œë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        prompt_path: tone í…œí”Œë¦¿ íŒŒì¼ ê²½ë¡œ
        influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ (ì„ íƒì‚¬í•­)
        persona_context: í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    """
    loader = ToneAwarePromptLoader(prompt_path=prompt_path, influencer_name=influencer_name, persona_context=persona_context)
    return loader.load()


def setup_influencer_persona(influencer_name: str):
    """
    ì¸í”Œë£¨ì–¸ì„œì˜ Toneê³¼ í˜ë¥´ì†Œë‚˜ë¥¼ ì„¤ì •í•˜ê³  ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
        influencer_name: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
    """
    # AIë¥¼ ì‚¬ìš©í•˜ì—¬ Tone ì„ íƒ
    chat_model = load_cached_chat_model("claude-3-7-sonnet-latest", st.session_state.anthropic_api_key)
    serpapi_key = st.session_state.get('serpapi_api_key', None)
    tone_selector = ToneSelector(chat_model, serpapi_key)

    # Tone ì„ íƒ (ë¡œê·¸ ìë™ ì¶œë ¥ë¨)
    tone_type, tone_file_path = tone_selector.select_tone(influencer_name)

    # í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    persona_context = tone_selector.fetch_persona_context(influencer_name)

    # ì„¸ì…˜ì— ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ë° Tone ì •ë³´ ì €ì¥
    st.session_state.influencer_name = influencer_name
    st.session_state.tone_type = tone_type
    st.session_state.tone_file_path = tone_file_path
    st.session_state.persona_context = persona_context
    st.session_state.setup_complete = True
    st.session_state.loading = False


# ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ í™”ë©´
def show_influencer_input_screen():
    """ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    # ë¡œë”© ìƒíƒœ í™•ì¸
    if st.session_state.get('loading', False):
        # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ì„ ì¤‘ì•™ì— í‘œì‹œ
        st.markdown("<br><br><br><br><br><br><br><br>", unsafe_allow_html=True)

        influencer_name = st.session_state.get('temp_influencer_name', '')

        # ì¤‘ì•™ ì •ë ¬ëœ í…ìŠ¤íŠ¸ì™€ í° ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ë§Œ í‘œì‹œ
        st.markdown(f"""
        <div style="text-align: center;">
            <h2>AI {influencer_name}ë¥¼ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤...</h2>
            <br><br>
            <div class="wave-loader-large">
                <div class="dot"></div>
                <div class="dot"></div>
                <div class="dot"></div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        return

    # ì¼ë°˜ ì…ë ¥ í™”ë©´
    st.title("ğŸŒŸ ë‚˜ë§Œì˜ AI ì¹œêµ¬ ë§Œë“¤ê¸°")
    st.markdown("### ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ì¸í”Œë£¨ì–¸ì„œì˜ ì´ë¦„ì„ ì¨ì£¼ì„¸ìš”")

    influencer_name = st.text_input(
        "ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„",
        placeholder="ì˜ˆ: ë°•ì‚¬ë‹˜, ìµœì• , ì¹œêµ¬ ì´ë¦„ ë“±...",
        key="influencer_name_input",
        label_visibility="collapsed"
    )

    _, col2, _ = st.columns([1, 1, 1])
    with col2:
        if st.button("ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
            if influencer_name.strip():
                # ë¡œë”© ìƒíƒœë¡œ ì „í™˜
                st.session_state.temp_influencer_name = influencer_name.strip()
                st.session_state.loading = True
                st.rerun()
            else:
                st.warning("ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")


# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ UI
def main():
    # ì‚¬ì´ë“œë°” í‘œì‹œ
    sidebar_api_input()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'setup_complete' not in st.session_state:
        st.session_state.setup_complete = False

    # API í‚¤ê°€ ë“±ë¡ë˜ì§€ ì•Šì€ ê²½ìš° ì•Œë¦¼ í‘œì‹œ
    if not st.session_state.get('api_key_submitted', False):
        st.info("ì±„íŒ…ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ Anthropic API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        st.chat_input("API í‚¤ë¥¼ ë¨¼ì € ë“±ë¡í•˜ì„¸ìš”", disabled=True)
        return

    # ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ í™”ë©´ í‘œì‹œ
    if not st.session_state.setup_complete:
        show_influencer_input_screen()

        # ë¡œë”© ìƒíƒœì¼ ë•Œ í˜ë¥´ì†Œë‚˜ ì„¤ì •
        if st.session_state.get('loading', False):
            influencer_name = st.session_state.get('temp_influencer_name', '')
            setup_influencer_persona(influencer_name)
            st.rerun()

        return

    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([3, 1])

    with col1:
        st.title("ğŸ’¬")
        st.markdown("""ì¹œí•œ ì¹œêµ¬ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”!
        ì–´ë–¤ ì¼ìƒ ì´ì•¼ê¸°ë“  í™˜ì˜ì´ì—ìš” ğŸ˜Š""")

    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    display_previous_messages()

    # API ëª¨ë¸ ë¡œë“œ
    chat_model = load_cached_chat_model("claude-3-7-sonnet-latest", st.session_state.anthropic_api_key)

    # ì„ íƒëœ Toneìœ¼ë¡œ ëŒ€í™” ì²´ì¸ êµ¬ì„±
    tone_file_path = st.session_state.get('tone_file_path', "prompts/converstation_prompt.md")
    influencer_name = st.session_state.get('influencer_name', None)
    persona_context = st.session_state.get('persona_context', None)

    # tone_file_path, influencer_name, persona_contextë¡œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt = load_cached_prompt(tone_file_path, influencer_name, persona_context)

    chain = prompt | chat_model
    conversation = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history"
    )

    # ì±„íŒ… ì…ë ¥ í™œì„±í™”
    if question := st.chat_input("ì˜¤ëŠ˜ ë­í–ˆì–´?"):
        # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥ ë° í‘œì‹œ
        st.session_state.messages.append({"role": "human", "content": question})
        with st.chat_message('human'):
            st.markdown(question)

        # ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        # ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •
        max_retries = 3
        retry_count = 0
        spinner_placeholder = st.empty()
        error_placeholder = st.empty()
        search_placeholder = st.empty()

        # ì‹ ì¡°ì–´/ëª¨ë¥´ëŠ” ìš©ì–´ ë° ì¸ë¬¼/ì‚¬ê±´ ê°ì§€ ë° ê²€ìƒ‰
        search_context = ""
        try:
            # Detector ì´ˆê¸°í™”
            term_detector = TermDetector(chat_model)
            entity_detector = EntityDetector(chat_model)

            # ìš©ì–´ ê°ì§€
            search_placeholder.markdown("ğŸ” ìš©ì–´ í™•ì¸ ì¤‘...", unsafe_allow_html=True)
            term_needs_search, term_search_term = term_detector.detect(question)

            # ì¸ë¬¼/ì‚¬ê±´ ê°ì§€ (influencer_name ì „ë‹¬)
            search_placeholder.markdown("ğŸ” ì¸ë¬¼/ì‚¬ê±´ í™•ì¸ ì¤‘...", unsafe_allow_html=True)
            entity_needs_search, entity_search_term = entity_detector.detect(question, influencer_name)

            # ê²€ìƒ‰í•  ìš©ì–´ ê²°ì • (ìš°ì„ ìˆœìœ„: ì¸ë¬¼/ì‚¬ê±´ > ì‹ ì¡°ì–´)
            needs_search = entity_needs_search or term_needs_search
            search_term = entity_search_term if entity_needs_search else term_search_term

            if needs_search and search_term:
                # ê²€ìƒ‰ ìˆ˜í–‰
                search_placeholder.markdown(f"ğŸ” '{search_term}' ê²€ìƒ‰ ì¤‘...", unsafe_allow_html=True)

                # SearchService ì´ˆê¸°í™” (SerpAPI í‚¤ í•„ìš”)
                serpapi_key = st.session_state.get('serpapi_api_key', None)
                if serpapi_key:
                    search_service = SearchService(api_key=serpapi_key)
                    search_results = search_service.search(search_term)
                    search_summary = search_service.extract_summary(search_results)

                    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                    search_context = f"\n\n[ê²€ìƒ‰ ì •ë³´: '{search_term}']\n{search_summary}\n"
                    print(f"[Search] ê²€ìƒ‰ ì™„ë£Œ: {search_context}")
                else:
                    print("[Search] SerpAPI í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")

            search_placeholder.empty()
        except Exception as e:
            print(f"[Search] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            search_placeholder.empty()

        while retry_count < max_retries:
            try:
                # ëŒ€í™” ì²´ì¸ì„ í†µí•œ ì‘ë‹µ ìƒì„±
                spinner_placeholder.markdown('<div class="wave-loader"><div class="dot"></div><div class="dot"></div><div class="dot"></div></div>', unsafe_allow_html=True)

                # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì§ˆë¬¸ì— ì¶”ê°€
                enhanced_question = question + search_context
                
                result = conversation.invoke(
                    {"input": enhanced_question},
                    config={"configurable": {"session_id": "default"}}
                )
                response = result.content

                # # ì‘ë‹µì— ë§ëŠ” ì´ë¯¸ì§€ ì„ íƒ
                # selected_image = select_image_for_context(response)

                # Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ë§¥ë½ ë‹¨ìœ„ë¡œ ë¶„í• 
                split_parts = split_response_by_context(response, chat_model)

                spinner_placeholder.empty()
                error_placeholder.empty()

                # ë¶„í• ëœ ë‹µë³€ì„ ê°œë³„ ë©”ì‹œì§€ë¡œ í‘œì‹œ
                for i, part in enumerate(split_parts):
                    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ì•„ë‹ˆë©´ íƒ€ì´í•‘ ì¤‘ í‘œì‹œ
                    if i > 0:
                        typing_placeholder = st.empty()
                        typing_placeholder.markdown('<div class="wave-loader"><div class="dot"></div><div class="dot"></div><div class="dot"></div></div>', unsafe_allow_html=True)

                        # ë‹µë³€ ê¸¸ì´ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ëŒ€ê¸° ì‹œê°„ ê³„ì‚° (ìµœì†Œ 4ì´ˆ, ìµœëŒ€ 10ì´ˆ)
                        char_count = len(part)
                        typing_delay = min(max(4, char_count / 50), 10)  # 50ìë‹¹ 1ì´ˆ, ìµœì†Œ 4ì´ˆ, ìµœëŒ€ 10ì´ˆ
                        time.sleep(typing_delay)

                        typing_placeholder.empty()

                    with st.chat_message('assistant'):
                        st.markdown(part)

                # # ì´ë¯¸ì§€ í‘œì‹œ (ì„ íƒëœ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°)
                # if selected_image:
                #     st.image(selected_image, width=200)

                # ë©”ì‹œì§€ ì €ì¥ (ì´ë¯¸ì§€ ê²½ë¡œë„ í•¨ê»˜ ì €ì¥)
                message_data = {"role": "assistant", "content": response}
                # if selected_image:
                #     message_data["image"] = selected_image
                st.session_state.messages.append(message_data)
                break  # ì„±ê³µí•˜ë©´ ë°˜ë³µ ì¤‘ë‹¨

            except Exception as e:
                error_text = str(e)
                retry_count += 1
                spinner_placeholder.empty()

                # ì˜¤ë¥˜ íƒ€ì… í™•ì¸ ë° ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ ìƒì„±
                if "overloaded_error" in error_text or "529" in error_text:
                    if retry_count < max_retries:
                        with error_placeholder.container():
                            with st.chat_message('assistant'):
                                st.warning(f"âš ï¸ ì¬ì‹œë„ ì¤‘... ({retry_count}/{max_retries})")
                        time.sleep(2)  # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
                    else:
                        spinner_placeholder.empty()
                        error_placeholder.empty()
                        error_final = "âš ï¸ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        with st.chat_message('assistant'):
                            st.error(error_final)
                        st.session_state.messages.append({"role": "assistant", "content": error_final})
                else:
                    spinner_placeholder.empty()
                    error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_text}"
                    with st.chat_message('assistant'):
                        st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    break  # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ

if __name__ == "__main__":
    main()
