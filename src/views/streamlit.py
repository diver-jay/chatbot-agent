import streamlit as st
import time
from langchain_core.runnables.history import RunnableWithMessageHistory

# ë¶„ë¦¬ëœ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain.prompts import ChatPromptTemplate
from langchain_core.prompts import MessagesPlaceholder
from src.models.model_factory import ChatModelFactory
from src.models.session_manager import StreamlitSessionManager
from src.views.ui_components import StreamlitUIComponent
from src.agents.tone_select_agent import ToneSelectAgent
from src.agents.response_split_agent import ResponseSplitAgent
from src.agents.persona_extract_agent import PersonaExtractAgent
from src.services.search_orchestrator import SearchOrchestrator

# SessionManager ë° UIComponent ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
session_manager = StreamlitSessionManager()
ui_component = StreamlitUIComponent()


def configure_page():
    """í˜ì´ì§€ ì„¤ì •ì„ êµ¬ì„±í•©ë‹ˆë‹¤."""
    st.set_page_config(page_title="ì‹¬ì‹¬ì´ ìŠ¤íƒ€ì¼ ì±—ë´‡", page_icon="ğŸ˜Š", layout="wide")


def apply_custom_css():
    """ì»¤ìŠ¤í…€ ìŠ¤í”¼ë„ˆ CSSë¥¼ ì ìš©í•©ë‹ˆë‹¤."""
    st.markdown(
        """
<style>
.wave-loader {
    display: flex;
    justify-content: flex-start;
    align-items: center;
    gap: 4px;
    padding: 8px 0;
    margin-left: 20px;
}
.wave-loader .dot {
    width: 6px;
    height: 6px;
    background-color: #ff4b4b;
    border-radius: 50%;
    animation: wave 1.2s ease-in-out infinite;
}
.wave-loader .dot:nth-child(1) {
    animation-delay: 0s;
}
.wave-loader .dot:nth-child(2) {
    animation-delay: 0.2s;
}
.wave-loader .dot:nth-child(3) {
    animation-delay: 0.4s;
}
@keyframes wave {
    0%, 60%, 100% {
        transform: translateY(0);
    }
    30% {
        transform: translateY(-10px);
    }
}

/* ë¡œë”© í™”ë©´ìš© í° wave-loader */
.wave-loader-large {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 12px;
    padding: 20px 0;
}
.wave-loader-large .dot {
    width: 20px;
    height: 20px;
    background-color: #ff4b4b;
    border-radius: 50%;
    animation: wave 1.2s ease-in-out infinite;
}
.wave-loader-large .dot:nth-child(1) {
    animation-delay: 0s;
}
.wave-loader-large .dot:nth-child(2) {
    animation-delay: 0.2s;
}
.wave-loader-large .dot:nth-child(3) {
    animation-delay: 0.4s;
}

/* ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ì•„ë°”íƒ€ ì˜ì—­ ìˆ¨ê¸°ê¸° */
[data-testid="stChatMessageAvatarUser"] {
    display: none !important;
}

/* SNS ì¸ë„¤ì¼ hover íš¨ê³¼ */
.stMarkdown a img {
    transition: all 0.3s ease;
}
.stMarkdown a img:hover {
    opacity: 0.8;
    transform: scale(1.02);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
}
</style>
""",
        unsafe_allow_html=True,
    )


@st.cache_resource(show_spinner=False)
def load_cached_chat_model(model_name, api_key):
    return ChatModelFactory.create_model(model_name, api_key)


@st.cache_data()
def load_cached_prompt(prompt_path, influencer_name=None, persona_context=None):
    """
    ì§€ì •ëœ tone íŒŒì¼ ê²½ë¡œë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•˜ê³  í˜ë¥´ì†Œë‚˜ë¥¼ ì£¼ì…í•©ë‹ˆë‹¤.
    """
    try:
        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
        with open(prompt_path, "r", encoding="utf-8") as f:
            prompt_content = f.read()

        # ========== ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€ ==========
        print("\n" + "=" * 80)
        print("[DEBUG] load_cached_prompt - í”„ë¡¬í”„íŠ¸ ë¡œë“œ")
        print("=" * 80)
        print(f"í”„ë¡¬í”„íŠ¸ ê²½ë¡œ: {prompt_path}")
        print(f"ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„: {influencer_name}")

        # {chat_histories} í”Œë ˆì´ìŠ¤í™€ë” ì²´í¬
        if "{chat_histories}" in prompt_content:
            print("âœ… {chat_histories} í”Œë ˆì´ìŠ¤í™€ë” ë°œê²¬")
        else:
            print("âŒ {chat_histories} í”Œë ˆì´ìŠ¤í™€ë” ì—†ìŒ")
        print("=" * 80 + "\n")
        # ========================================

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì£¼ì…
        if influencer_name:
            persona_injection = f"\n\n**ì¤‘ìš”**: ë‹¹ì‹ ì€ '{influencer_name}' ë³¸ì¸ì…ë‹ˆë‹¤. íŒ¬ë“¤ì´ '{influencer_name}ë‹˜ íŒ¬ì´ì—ìš”' ë˜ëŠ” '{influencer_name} ì¢‹ì•„í•´ìš”'ë¼ê³  ë§í•˜ë©´, {influencer_name}ì„ ì œ3ìë¡œ ì–¸ê¸‰í•˜ì§€ ë§ê³  ë³¸ì¸ì˜ ì‹œì ('ë‚˜')ì—ì„œ ë‹µë³€í•˜ì„¸ìš”.\n"

            # í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if persona_context:
                persona_injection += f"\n**ë‹¹ì‹ ì˜ ë°°ê²½ ì •ë³´**:\n{persona_context}\n\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì„¸ìš”. íŠ¹íˆ ì¼ìƒ ì§ˆë¬¸ì´ë‚˜ ìµœê·¼ ê·¼í™©ì„ ë¬¼ì–´ë³¼ ë•Œ ì´ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n"

            prompt_content = prompt_content + persona_injection
            print(f"[DEBUG] prompt_content:\n{prompt_content}\n")

        return ChatPromptTemplate.from_messages(
            [
                ("system", prompt_content),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}"),
            ]
        )
    except FileNotFoundError as e:
        raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")


def setup_influencer_persona(influencer_name: str):
    """
    ì¸í”Œë£¨ì–¸ì„œì˜ Toneê³¼ í˜ë¥´ì†Œë‚˜ë¥¼ ì„¤ì •í•˜ê³  ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    ìµœì í™”: Tone ì„ íƒê³¼ í˜ë¥´ì†Œë‚˜ ì¶”ì¶œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ ì†ë„ ê°œì„  (4-10ì´ˆ â†’ 2-5ì´ˆ)

    Args:
        influencer_name: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
    """
    from concurrent.futures import ThreadPoolExecutor

    chat_model = load_cached_chat_model(
        "claude-3-7-sonnet-latest", session_manager.get_api_key()
    )
    tone_select_agent = ToneSelectAgent(chat_model)
    persona_extract_agent = PersonaExtractAgent(chat_model)

    # ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì†ë„ ê°œì„ 
    with ThreadPoolExecutor(max_workers=2) as executor:
        tone_future = executor.submit(
            tone_select_agent.act, influencer_name=influencer_name
        )
        persona_future = executor.submit(
            persona_extract_agent.act, influencer_name=influencer_name
        )

        tone_future.result()  # Wait for tone selection to complete
        persona_context = persona_future.result()

        tone_file_path = tone_select_agent.get_tone_path()

    # ì„¸ì…˜ì— ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ë° Tone ì •ë³´ ì €ì¥
    session_manager.save_influencer_setup(
        influencer_name, tone_file_path, persona_context
    )


# ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ í™”ë©´
def show_influencer_input_screen():
    """ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    # ë¡œë”© ìƒíƒœ í™•ì¸
    if session_manager.is_loading():
        # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ì„ ì¤‘ì•™ì— í‘œì‹œ
        st.markdown("<br><br><br><br><br><br><br><br>", unsafe_allow_html=True)

        influencer_name = session_manager.get_temp_influencer_name()

        # ì¤‘ì•™ ì •ë ¬ëœ í…ìŠ¤íŠ¸ì™€ í° ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ë§Œ í‘œì‹œ
        st.markdown(
            f"""
        <div style="text-align: center;">
            <h2>AI {influencer_name}ë¥¼ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤...</h2>
            <br><br>
            <div class="wave-loader-large">
                <div class="dot"></div>
                <div class="dot"></div>
                <div class="dot"></div>
            </div>
        </div>
        """,
            unsafe_allow_html=True,
        )
        return

    # ì¼ë°˜ ì…ë ¥ í™”ë©´
    st.title("ğŸŒŸ ë‚˜ë§Œì˜ AI ì¹œêµ¬ ë§Œë“¤ê¸°")
    st.markdown("### ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ì¸í”Œë£¨ì–¸ì„œì˜ ì´ë¦„ì„ ì¨ì£¼ì„¸ìš”")

    influencer_name = st.text_input(
        "ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„",
        placeholder="ì˜ˆ: ë°•ì‚¬ë‹˜, ìµœì• , ì¹œêµ¬ ì´ë¦„ ë“±...",
        key="influencer_name_input",
        label_visibility="collapsed",
    )

    _, col2, _ = st.columns([1, 1, 1])
    with col2:
        if st.button("ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
            if influencer_name.strip():
                # ë¡œë”© ìƒíƒœë¡œ ì „í™˜
                session_manager.set_loading_state(influencer_name)
                st.rerun()
            else:
                st.warning("ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")


def generate_response(question, conversation, search_context, sns_content):
    """
    ëŒ€í™” ì²´ì¸ì„ í†µí•´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
        str: ìƒì„±ëœ ì‘ë‹µ
    """
    # ìµœê·¼ 3ê°œì˜ ëŒ€í™” ìŒ ê°€ì ¸ì˜¤ê¸°
    recent_turns = session_manager.get_recent_conversation_turns(2)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
    chat_histories = ""
    if recent_turns:
        for idx, turn in enumerate(recent_turns, 1):
            chat_histories += f"[ëŒ€í™” {idx}]\n"
            chat_histories += f"User: {turn['user']}\n"
            chat_histories += f"AI: {turn['ai']}\n\n"

    # ========== ë””ë²„ê¹… ë¡œê·¸ ==========
    print("\n" + "=" * 80)
    print("[DEBUG] generate_response - ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶„ì„")
    print("=" * 80)
    print(f"ìµœê·¼ ëŒ€í™” í„´ ê°œìˆ˜: {len(recent_turns)}")
    print(
        f"\nchat_histories ë‚´ìš©:\n{chat_histories if chat_histories else '(ë¹„ì–´ìˆìŒ)'}"
    )
    print("=" * 80 + "\n")
    # ===================================

    # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì§ˆë¬¸ì— ì¶”ê°€
    enhanced_question = question + search_context

    # SNS ì½˜í…ì¸ ê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì§€ì‹œì‚¬í•­ ì‚½ì…
    if sns_content and sns_content.get("found"):
        platform = sns_content.get("platform", "")
        platform_name = "ì¸ìŠ¤íƒ€ê·¸ë¨" if platform == "instagram" else "ìœ íŠœë¸Œ"

        print(
            f"[Response Generation] âœ… SNS ì½˜í…ì¸  ë°œê²¬ â†’ AIì—ê²Œ {platform_name} ê²Œì‹œë¬¼ ì§‘ì¤‘ ì§€ì‹œ"
        )
        sns_instruction = f"""

[ì¤‘ìš” ì§€ì‹œì‚¬í•­]
ë‹µë³€ì€ ë°˜ë“œì‹œ ìœ„ì˜ {platform_name} ê²Œì‹œë¬¼ ë‚´ìš©ì— ëŒ€í•´ì„œë§Œ ì´ì•¼ê¸°í•˜ì„¸ìš”.
ë‹¤ë¥¸ ê²€ìƒ‰ ì •ë³´ëŠ” ë¬´ì‹œí•˜ê³ , ì˜¤ì§ {platform_name} ê²Œì‹œë¬¼ ì£¼ì œì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.

ë‹µë³€ ë°©ì‹:
- ìì—°ìŠ¤ëŸ½ê²Œ "{platform_name}ì— ì˜¬ë ¸ëŠ”ë° ë´¤ì–´?", "ì–´ì œ {platform_name}ì— ì˜¬ë¦° ê±° ìˆëŠ”ë°~" ê°™ì€ í‘œí˜„ ì‚¬ìš©
- SNS ë§í¬ URLì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš” (ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì²¨ë¶€)
- **ë§¤ìš° ê°„ë‹¨í•˜ê²Œ 1-2ë¬¸ì¥ìœ¼ë¡œë§Œ ì†Œê°œ**í•˜ê³  ëë‚´ì„¸ìš” (ìƒì„¸í•œ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”)
- ì˜ˆì‹œ: "ì•„, í˜¹ì‹œ ìœ íŠœë¸Œì— ì˜¬ë¦° ì˜ìƒ ë³´ì…¨ë‚˜ìš”? [ì£¼ì œ]ì— ê´€í•œ ë‚´ìš©ì´ì—ˆì–´ìš”..." ì •ë„ë¡œë§Œ ë§í•˜ê³  ë
"""
        enhanced_question += sns_instruction
    else:
        print(f"[Response Generation] âŒ SNS ì½˜í…ì¸  ì—†ìŒ â†’ ì¼ë°˜ ë‹µë³€")

    # ========== ìµœì¢… ì „ë‹¬ íŒŒë¼ë¯¸í„° ë””ë²„ê¹… ==========
    print("\n" + "=" * 80)
    print("[DEBUG] conversation.invoke - ìµœì¢… ì „ë‹¬ íŒŒë¼ë¯¸í„°")
    print("=" * 80)
    print(f"enhanced_question ê¸¸ì´: {len(enhanced_question)}")
    print(f"enhanced_question ì• 200ì:\n{enhanced_question[:200]}")
    print(f"\nchat_historiesê°€ ë¹„ì–´ìˆë‚˜? {len(chat_histories) == 0}")
    print(f"chat_histories ê¸¸ì´: {len(chat_histories)}")
    print("=" * 80 + "\n")
    # ===============================================

    result = conversation.invoke(
        {"input": enhanced_question, "chat_histories": chat_histories},
        config={"configurable": {"session_id": "default"}},
    )
    return result.content


def display_response(
    split_parts,
    sns_content,
    is_media_requested,
    ui_component,
    session_manager,
    spinner_context,
    spinner_placeholder,
):
    """
    ë¶„í• ëœ ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•˜ê³  ì„¸ì…˜ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    for i, part in enumerate(split_parts):
        if i == 0:
            # ì²« ë²ˆì§¸ ë©”ì‹œì§€ëŠ” ìŠ¤í”¼ë„ˆë¥¼ ëŒ€ì²´
            spinner_placeholder.markdown(part)
            spinner_context.__exit__(None, None, None)

            # SNS ì½˜í…ì¸ ê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ
            if sns_content and sns_content.get("found"):
                platform = sns_content.get("platform", "")
                url = sns_content.get("url", "")
                thumbnail = sns_content.get("thumbnail", "")

                # ì¸ë„¤ì¼ í‘œì‹œ (Instagram: ì´ë¯¸ì§€ë§Œ, YouTube: í´ë¦­ ê°€ëŠ¥í•œ ë§í¬)
                if thumbnail:
                    if platform == "instagram":
                        # Instagram: ë§í¬ ì—†ì´ ì´ë¯¸ì§€ë§Œ í‘œì‹œ
                        st.markdown(
                            f"""
                            <img src="{thumbnail}" width="300" style="border-radius: 8px; display: block;">
                            """,
                            unsafe_allow_html=True,
                        )
                    elif platform == "youtube":
                        # YouTube: ì¸ë„¤ì¼ì„ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ í‘œì‹œ
                        st.markdown(
                            f"""
                            <a href="{url}" target="_blank" style="text-decoration: none;">
                                <img src="{thumbnail}" width="300" style="border-radius: 8px; cursor: pointer; display: block; transition: opacity 0.2s;">
                            </a>
                            """,
                            unsafe_allow_html=True,
                        )
                    else:
                        # ê·¸ ì™¸ í”Œë«í¼ì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
                        return

                # SNS ì½˜í…ì¸ ì™€ í•¨ê»˜ ë©”ì‹œì§€ ì €ì¥
                session_manager.add_message("assistant", part, sns_content=sns_content)
            else:
                # SNS ì½˜í…ì¸  ì—†ì´ ë©”ì‹œì§€ ì €ì¥
                session_manager.add_message("assistant", part)
        else:
            # ë‘ ë²ˆì§¸ ë©”ì‹œì§€ë¶€í„°ëŠ” íƒ€ì´í•‘ ì¤‘ í‘œì‹œ í›„ ìƒˆ ë©”ì‹œì§€
            typing_context, typing_placeholder = ui_component.display_typing_animation(
                len(part)
            )
            typing_placeholder.markdown(part)
            typing_context.__exit__(None, None, None)
            session_manager.add_message("assistant", part)


# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ UI
def run_app():
    # ì‚¬ì´ë“œë°” í‘œì‹œ
    ui_component.sidebar_api_input()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    session_manager.initialize_session_state()

    # API í‚¤ê°€ ë“±ë¡ë˜ì§€ ì•Šì€ ê²½ìš° ì•Œë¦¼ í‘œì‹œ
    if not session_manager.is_api_key_submitted():
        st.info("ì±„íŒ…ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ Anthropic API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        st.chat_input("API í‚¤ë¥¼ ë¨¼ì € ë“±ë¡í•˜ì„¸ìš”", disabled=True)
        return

    # ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ì…ë ¥ í™”ë©´ í‘œì‹œ
    if not session_manager.is_setup_complete():
        show_influencer_input_screen()

        # ë¡œë”© ìƒíƒœì¼ ë•Œ í˜ë¥´ì†Œë‚˜ ì„¤ì •
        if session_manager.is_loading():
            influencer_name = session_manager.get_temp_influencer_name()
            setup_influencer_persona(influencer_name)
            st.rerun()

        return

    # ì±„íŒ… í—¤ë” ë° ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    ui_component.display_chat_header()

    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    ui_component.display_previous_messages()

    # API ëª¨ë¸ ë¡œë“œ
    chat_model = load_cached_chat_model(
        "claude-3-7-sonnet-latest", session_manager.get_api_key()
    )

    # SearchOrchestrator ì´ˆê¸°í™”
    orchestrator = SearchOrchestrator(chat_model, session_manager)

    # ResponseSplitAgent ì´ˆê¸°í™”
    response_split_agent = ResponseSplitAgent(chat_model)

    # ì„ íƒëœ Toneìœ¼ë¡œ ëŒ€í™” ì²´ì¸ êµ¬ì„±
    tone_file_path = session_manager.get_tone_file_path()
    influencer_name = session_manager.get_influencer_name()
    persona_context = session_manager.get_persona_context()

    # tone_file_path, influencer_name, persona_contextë¡œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt = load_cached_prompt(tone_file_path, influencer_name, persona_context)

    chain = prompt | chat_model
    conversation = RunnableWithMessageHistory(
        chain,
        session_manager.get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history",
    )

    # ì±„íŒ… ì…ë ¥ í™œì„±í™”
    if question := ui_component.get_chat_input(""):
        # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥ ë° í‘œì‹œ
        ui_component.display_user_message(question)
        session_manager.add_message("human", question)

        # 1. ì§ˆë¬¸ ë¶„ì„ (Orchestratorì— ìœ„ì„)
        orchestrator.analyze_question(question, influencer_name)

        # 2. ê²€ìƒ‰ ì‹¤í–‰ (Orchestratorì— ìœ„ì„)
        search_context = ""
        sns_content = None
        if orchestrator.needs_search:
            search_context, sns_content = orchestrator.execute_search(question)

        # 3. ì‘ë‹µ ìƒì„± ë° í‘œì‹œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        max_retries = 3
        retry_count = 0

        # ìŠ¤í”¼ë„ˆë¥¼ ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…ìŠ¤íŠ¸ ì•ˆì— í‘œì‹œ
        spinner_context, spinner_placeholder = ui_component.create_assistant_spinner()
        error_placeholder = st.empty()

        while retry_count < max_retries:
            try:
                # 3-1. ì‘ë‹µ ìƒì„±
                response = generate_response(
                    question, conversation, search_context, sns_content
                )

                # 3-2. ì‘ë‹µ ë¶„í• 
                split_parts = response_split_agent.act(response=response)

                error_placeholder.empty()

                # 3-3. ì‘ë‹µ í‘œì‹œ
                display_response(
                    split_parts,
                    sns_content,
                    orchestrator.is_media_requested,
                    ui_component,
                    session_manager,
                    spinner_context,
                    spinner_placeholder,
                )

                # 3-4. ëŒ€í™” ìŒ ì €ì¥ (ì§ˆë¬¸ ì²´í¬ìš©)
                session_manager.add_conversation_turn(question, response)

                break  # ì„±ê³µí•˜ë©´ ë°˜ë³µ ì¤‘ë‹¨

            except Exception as e:
                error_text = str(e)
                retry_count += 1
                spinner_placeholder.empty()

                # ì˜¤ë¥˜ íƒ€ì… í™•ì¸ ë° ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ ìƒì„±
                if "overloaded_error" in error_text or "529" in error_text:
                    if retry_count < max_retries:
                        with error_placeholder.container():
                            ui_component.display_assistant_warning(
                                f"âš ï¸ ì¬ì‹œë„ ì¤‘... ({retry_count}/{max_retries})"
                            )
                        time.sleep(2)  # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
                    else:
                        spinner_placeholder.empty()
                        error_placeholder.empty()
                        error_final = "âš ï¸ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        ui_component.display_assistant_error(error_final)
                        session_manager.add_message("assistant", error_final)
                else:
                    spinner_placeholder.empty()
                    error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_text}"
                    ui_component.display_assistant_error(error_msg)
                    session_manager.add_message("assistant", error_msg)
                    break  # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
