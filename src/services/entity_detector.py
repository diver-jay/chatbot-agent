"""
ì‚¬ìš©ì ì…ë ¥ì—ì„œ íŠ¹ì • ì¸ë¬¼/ì‚¬ê±´ì„ ê°ì§€í•˜ëŠ” ëª¨ë“ˆ
"""
from typing import Tuple, Optional
import json
from langchain_core.messages import HumanMessage


class EntityDetector:
    """íŠ¹ì • ì¸ë¬¼ ë° ì‚¬ê±´ì„ ê°ì§€í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, chat_model):
        """
        Args:
            chat_model: LangChain ì±„íŒ… ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        """
        self.chat_model = chat_model

    def detect(self, user_message: str, influencer_name: Optional[str] = None, chat_history: Optional[list] = None) -> Tuple[bool, Optional[str], bool]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œ ì¸ë¬¼/ì‚¬ê±´ì„ ê°ì§€í•©ë‹ˆë‹¤.

        Args:
            user_message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ (ì„ íƒì‚¬í•­)
            chat_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì‚¬í•­) - [{"role": "human/assistant", "content": "..."}, ...]

        Returns:
            (ê²€ìƒ‰ í•„ìš” ì—¬ë¶€, ê²€ìƒ‰í•  ìš©ì–´, ì¼ìƒ ê´€ë ¨ ì—¬ë¶€) íŠœí”Œ
        """
        try:
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ íŒŒì¼ì—ì„œ ë¡œë“œ
            prompt_template_path = "prompts/entity_detection_prompt.md"

            with open(prompt_template_path, "r", encoding="utf-8") as f:
                prompt_template = f.read()

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
            history_context = ""
            if chat_history:
                # ìµœê·¼ 4ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© (2í„´)
                recent_history = chat_history[-4:] if len(chat_history) > 4 else chat_history
                history_lines = []
                for msg in recent_history:
                    role = "ì‚¬ìš©ì" if msg.get("role") == "human" else "AI"
                    content = msg.get("content", "")
                    history_lines.append(f"{role}: {content}")
                history_context = "\n".join(history_lines)

            # í…œí”Œë¦¿ì— ë³€ìˆ˜ ì£¼ì…
            if history_context:
                detection_prompt = prompt_template.format(
                    user_message=f"[ì´ì „ ëŒ€í™”]\n{history_context}\n\n[í˜„ì¬ ì§ˆë¬¸]\n{user_message}"
                )
            else:
                detection_prompt = prompt_template.format(user_message=user_message)

            # LLMì„ ì‚¬ìš©í•˜ì—¬ ì¸ë¬¼/ì‚¬ê±´ ê°ì§€
            response = self.chat_model.invoke([HumanMessage(content=detection_prompt)])

            # JSON ì‘ë‹µ íŒŒì‹±
            response_text = response.content.strip()

            # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
            if response_text.startswith("```json"):
                response_text = response_text.replace("```json", "").replace("```", "").strip()
            elif response_text.startswith("```"):
                response_text = response_text.replace("```", "").strip()

            result = json.loads(response_text)

            needs_search = result.get("needs_search", False)
            search_term = result.get("search_term", None)
            is_daily_life = result.get("is_daily_life", False)

            # influencer_nameì´ ìˆê³ , search_termì— ì•„ì§ í¬í•¨ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì•ì— ì¶”ê°€
            if needs_search and search_term and influencer_name:
                # "ì¸ë¬¼ëª…" í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‹¤ì œ ì´ë¦„ìœ¼ë¡œ ì¹˜í™˜
                if "ì¸ë¬¼ëª…" in search_term:
                    search_term = search_term.replace("ì¸ë¬¼ëª…", influencer_name)
                # ì´ë¯¸ influencer_nameì´ search_termì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                elif influencer_name.lower() not in search_term.lower():
                    search_term = f"{influencer_name} {search_term}"

            print(f"[EntityDetector] ğŸ” ê²€ìƒ‰ í•„ìš”: {needs_search} | ê²€ìƒ‰ì–´: {search_term} | ì¼ìƒ: {is_daily_life} | íŒë‹¨ ê·¼ê±°: {result.get('reason', 'N/A')}")

            return needs_search, search_term, is_daily_life

        except Exception as e:
            print(f"[EntityDetector] Error: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê²€ìƒ‰í•˜ì§€ ì•ŠìŒ
            return False, None, False
