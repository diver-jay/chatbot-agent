from abc import ABC, abstractmethod
import os
from typing import Tuple, Optional, Dict, Any, List
from datetime import datetime, timedelta
import requests
import concurrent.futures

from src.utils.logger import log
from src.utils.date_utils import get_formatted_date
from src.utils.decorators import retry_on_error


class SearchService(ABC):
    """ê²€ìƒ‰ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì¸í„°íŽ˜ì´ìŠ¤"""

    @abstractmethod
    def search(self, query: str, question: str) -> Tuple[str, Optional[Dict[str, Any]]]:
        pass


class NoSearchService(SearchService):
    """ê²€ìƒ‰ì´ í•„ìš” ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤"""

    def search(self, query: str, question: str) -> Tuple[str, Optional[Dict[str, Any]]]:
        log(self.__class__.__name__, "â†’ ê²€ìƒ‰ í•„ìš” ì—†ìŒ ê²½ë¡œ")
        return "", None


class GeneralSearchService(SearchService):
    """ì¼ë°˜ì ì¸ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.api_key = os.getenv("SERPAPI_API_KEY")
        self.serpapi_base_url = os.getenv("SERPAPI_BASE_URL", "https://serpapi.com/search")

    @retry_on_error(max_attempts=2, delay=2.0)
    def search(self, query: str, question: str) -> Tuple[str, Optional[Dict[str, Any]]]:
        log(self.__class__.__name__, "â†’ ì¼ë°˜ ì¸ë¬¼/ì‚¬ê±´ ê²€ìƒ‰ ê²½ë¡œ")
        if not self.api_key:
            log(self.__class__.__name__, "SerpAPI í‚¤ê°€ ì—†ì–´ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return "", None

        current_date = get_formatted_date(datetime.now())
        search_results = self._search_web(query)
        search_summary = self._extract_summary(search_results)

        search_context = f"\n\n[ê²€ìƒ‰ ì •ë³´: '{query}']\n{search_summary}\n\n[ì°¸ê³ ] ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}\n"
        log(self.__class__.__name__, "ê²€ìƒ‰ ì™„ë£Œ")
        return search_context, None

    def _search_web(self, query: str, num_results: int = 3) -> Dict[str, Any]:
        try:
            params = {
                "q": query,
                "api_key": self.api_key,
                "num": num_results,
                "hl": "ko",
                "gl": "kr",
            }
            response = requests.get(self.serpapi_base_url, params=params, timeout=10)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            log(self.__class__.__name__, f"SerpAPI ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _extract_summary(self, search_results: Dict[str, Any]) -> str:
        if "error" in search_results:
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {search_results['error']}"
        if "answer_box" in search_results and search_results["answer_box"].get(
            "answer"
        ):
            return f"âœ“ {search_results['answer_box']['answer']}"
        if "knowledge_graph" in search_results:
            kg = search_results["knowledge_graph"]
            return f"ðŸ“Œ {kg.get('title', '')}\n{kg.get('description', '')}"
        if "organic_results" in search_results and search_results["organic_results"]:
            return "\n".join(
                [
                    f"â€¢ {r.get('snippet', '')}"
                    for r in search_results["organic_results"][:3]
                ]
            )
        return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


class TermSearchService(SearchService):
    """ì‹ ì¡°ì–´/ìš©ì–´ ê²€ìƒ‰ì„ ìœ„í•œ ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.api_key = os.getenv("SERPAPI_API_KEY")
        self.serpapi_base_url = os.getenv("SERPAPI_BASE_URL", "https://serpapi.com/search")

    @retry_on_error(max_attempts=2, delay=2.0)
    def search(self, query: str, question: str) -> Tuple[str, Optional[Dict[str, Any]]]:
        log(self.__class__.__name__, "â†’ ì‹ ì¡°ì–´/ìš©ì–´ ê²€ìƒ‰ ê²½ë¡œ")
        if not self.api_key:
            log(self.__class__.__name__, "SerpAPI í‚¤ê°€ ì—†ì–´ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return "", None

        current_date = get_formatted_date(datetime.now())
        search_results = self._search_web(query)
        search_summary = self._extract_summary(search_results)

        search_context = f"\n\n[ê²€ìƒ‰ ì •ë³´: '{query}']\n{search_summary}\n\n[ì°¸ê³ ] ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}\n"
        search_context += f"\n[ì§€ì‹œì‚¬í•­] ìœ„ ê²€ìƒ‰ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìžì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”. ê²€ìƒ‰ì–´('{query}')ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ì§€ ë§ê³ , ê·¸ ì˜ë¯¸ë¥¼ ì´í•´í•œ ìƒíƒœë¡œ ëŒ€í™”í•˜ì„¸ìš”.\n"
        return search_context, None

    def _search_web(self, query: str, num_results: int = 3) -> Dict[str, Any]:
        try:
            params = {
                "q": query,
                "api_key": self.api_key,
                "num": num_results,
                "hl": "ko",
                "gl": "kr",
            }
            response = requests.get(self.serpapi_base_url, params=params, timeout=10)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            log(self.__class__.__name__, f"SerpAPI ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _extract_summary(self, search_results: Dict[str, Any]) -> str:
        if "error" in search_results:
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {search_results['error']}"
        if "answer_box" in search_results and search_results["answer_box"].get(
            "answer"
        ):
            return f"âœ“ {search_results['answer_box']['answer']}"
        if "knowledge_graph" in search_results:
            kg = search_results["knowledge_graph"]
            return f"ðŸ“Œ {kg.get('title', '')}\n{kg.get('description', '')}"
        if "organic_results" in search_results and search_results["organic_results"]:
            return "\n".join(
                [
                    f"â€¢ {r.get('snippet', '')}"
                    for r in search_results["organic_results"][:3]
                ]
            )
        return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


class SnsSearchService(SearchService):
    """SNS ì½˜í…ì¸ ë¥¼ ê²€ìƒ‰í•˜ê³ , ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ fallbackí•˜ëŠ” ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤"""

    def __init__(self, relevance_checker):
        self.api_key = os.getenv("SERPAPI_API_KEY")
        self.youtube_api_key = os.getenv("YOUTUBE_API_KEY")
        self.relevance_checker = relevance_checker
        self.serpapi_base_url = os.getenv("SERPAPI_BASE_URL", "https://serpapi.com/search")
        self.youtube_base_url = os.getenv("YOUTUBE_BASE_URL", "https://www.googleapis.com/youtube/v3/search")
        self._fallback_service = GeneralSearchService()

    @retry_on_error(max_attempts=2, delay=2.0)
    def search(self, query: str, question: str) -> Tuple[str, Optional[Dict[str, Any]]]:
        log(self.__class__.__name__, "â†’ ì¼ìƒ ì§ˆë¬¸ (SNS) ê²½ë¡œ")
        if not self.api_key:
            log(self.__class__.__name__, "SerpAPI í‚¤ê°€ ì—†ì–´ SNS ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return "", None

        sns_content = self._search_sns_content(query=query, user_question=question)

        if sns_content and sns_content.get("found"):
            log(self.__class__.__name__, f"âœ… ê´€ë ¨ SNS ì½˜í…ì¸  ë°œê²¬ â†’ SNS ì •ë³´ ì‚¬ìš©")
            platform_name = (
                "Instagram" if sns_content.get("platform") == "instagram" else "YouTube"
            )
            sns_title = sns_content.get("title", "")
            current_date = get_formatted_date(datetime.now())
            search_context = f"\n\n[{platform_name} ê²Œì‹œë¬¼ ì •ë³´]\n{sns_title}\n\n[ì°¸ê³ ] ì˜¤ëŠ˜ ë‚ ì§œ: {current_date}\n"
            return search_context, sns_content
        else:
            log(self.__class__.__name__, f"SNS ì½˜í…ì¸  ì—†ìŒ â†’ ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ Fallback")
            return self._fallback_service.search(query, question)

    def _search_sns_content(
        self, query: str, user_question: str = ""
    ) -> Dict[str, Any]:
        time_ranges = [
            ("qdr:m3", "ìµœê·¼ 3ê°œì›”"),
            ("qdr:m6", "ìµœê·¼ 6ê°œì›”"),
            ("qdr:y", "ìµœê·¼ 1ë…„"),
            (None, "ì „ì²´ ê¸°ê°„"),
        ]
        youtube_query = self._clean_youtube_query(query)

        all_candidates = self._search_all_time_ranges_parallel(
            query, youtube_query, time_ranges
        )
        if not all_candidates:
            return {"found": False}

        sorted_candidates = self._sort_by_recency(all_candidates)

        for candidate in sorted_candidates:
            if self.relevance_checker.act(
                user_question=user_question,
                sns_title=candidate.get("title", ""),
                platform=candidate.get("platform", ""),
                search_term=query,
            ):
                return {"found": True, **candidate}
        return {"found": False}

    def _clean_youtube_query(self, query: str) -> str:
        for keyword in ["ìœ íŠœë¸Œ", "youtube", "ì˜ìƒ", "ë™ì˜ìƒ", "ë¹„ë””ì˜¤", "video"]:
            query = (
                query.replace(keyword, "")
                .replace(keyword.upper(), "")
                .replace(keyword.capitalize(), "")
            )
        return " ".join(query.split())

    def _search_all_time_ranges_parallel(
        self, query: str, youtube_query: str, time_ranges: List[tuple]
    ) -> List[Dict[str, Any]]:
        all_candidates = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            futures = []
            for tbs, period in time_ranges:
                futures.append(
                    executor.submit(
                        self._search_google_images_with_metadata, query, tbs, period
                    )
                )
                if self.youtube_api_key:
                    futures.append(
                        executor.submit(
                            self._search_youtube_direct_with_metadata,
                            youtube_query,
                            self._get_youtube_time_filter(tbs),
                            period,
                        )
                    )

            for future in concurrent.futures.as_completed(futures):
                all_candidates.extend(future.result())

        seen_urls = set()
        unique_candidates = [
            c
            for c in all_candidates
            if c.get("url")
            and c["url"] not in seen_urls
            and not seen_urls.add(c["url"])
        ]
        return unique_candidates

    def _search_google_images_with_metadata(
        self, query: str, tbs_value: Optional[str], period_name: str
    ) -> List[Dict[str, Any]]:
        candidates = self._search_google_images(query, tbs_value)
        for c in candidates:
            c.update({"time_range_priority": period_name, "time_range_tbs": tbs_value})
        return candidates

    def _search_youtube_direct_with_metadata(
        self, query: str, published_after: Optional[str], period_name: str
    ) -> List[Dict[str, Any]]:
        candidates = self._search_youtube_direct(query, published_after)
        for c in candidates:
            c.update(
                {
                    "time_range_priority": period_name,
                    "time_range_published_after": published_after,
                }
            )
        return candidates

    def _sort_by_recency(
        self, candidates: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        order = {"ìµœê·¼ 3ê°œì›”": 0, "ìµœê·¼ 6ê°œì›”": 1, "ìµœê·¼ 1ë…„": 2, "ì „ì²´ ê¸°ê°„": 3}
        return sorted(
            candidates,
            key=lambda c: order.get(c.get("time_range_priority", "ì „ì²´ ê¸°ê°„"), 99),
        )

    def _search_google_images(
        self, query: str, tbs_value: Optional[str]
    ) -> List[Dict[str, Any]]:
        params = {
            "q": query,
            "api_key": self.api_key,
            "engine": "google_images",
            "num": 50,
            "hl": "ko",
            "gl": "kr",
        }
        if tbs_value:
            params["tbs"] = tbs_value
        try:
            response = requests.get(self.serpapi_base_url, params=params, timeout=30)
            response.raise_for_status()
            results = response.json().get("images_results", [])
            candidates = []
            for res in results:
                link = res.get("link", "")
                if "instagram.com" in link and ("/p/" in link or "/reel/" in link):
                    candidates.append(
                        {
                            "platform": "instagram",
                            "url": link,
                            "thumbnail": res.get("thumbnail"),
                            "title": res.get("title"),
                            "source": "google_images",
                        }
                    )
                elif "youtube.com/watch" in link or "youtu.be/" in link:
                    candidates.append(
                        {
                            "platform": "youtube",
                            "url": link,
                            "thumbnail": res.get("thumbnail"),
                            "title": res.get("title"),
                            "source": "google_images",
                        }
                    )
                if len(candidates) >= 5:
                    break
            return candidates
        except Exception as e:
            log(self.__class__.__name__, f"Google Images ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _search_youtube_direct(
        self, query: str, published_after: Optional[str]
    ) -> List[Dict[str, Any]]:
        if not self.youtube_api_key:
            return []
        params = {
            "part": "snippet",
            "q": query,
            "key": self.youtube_api_key,
            "type": "video",
            "maxResults": 5,
            "regionCode": "KR",
            "relevanceLanguage": "ko",
            "order": "relevance",
        }
        if published_after:
            params["publishedAfter"] = published_after
        try:
            response = requests.get(self.youtube_base_url, params=params, timeout=30)
            response.raise_for_status()
            items = response.json().get("items", [])
            return [
                {
                    "platform": "youtube",
                    "url": f"https://www.youtube.com/watch?v={item.get('id', {}).get('videoId')}",
                    "thumbnail": item.get("snippet", {})
                    .get("thumbnails", {})
                    .get("high", {})
                    .get("url"),
                    "title": item.get("snippet", {}).get("title"),
                    "source": "youtube_api_v3",
                }
                for item in items
                if item.get("id", {}).get("videoId")
            ]
        except Exception as e:
            log(self.__class__.__name__, f"YouTube Direct ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _get_youtube_time_filter(self, tbs_value: Optional[str]) -> Optional[str]:
        if not tbs_value:
            return None
        days = {"qdr:m3": 90, "qdr:m6": 180, "qdr:y": 365}.get(tbs_value)
        return (
            (datetime.utcnow() - timedelta(days=days)).strftime("%Y-%m-%dT%H:%M:%SZ")
            if days
            else None
        )
